{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, unicode_literals, print_function  # for compatibility with Python 2 and 3\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import quiver\n",
    "\n",
    "# change the following to %matplotlib notebook for interactive plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141592653589793"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import math\n",
    "import scipy\n",
    "from scipy.spatial import Delaunay\n",
    "math.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pims #  Python Image Sequence see https://github.com/soft-matter/pims                         \n",
    "import trackpy as tp # Package for particle tracking in 2D, 3D, and higher dimensions\n",
    "from skimage import util\n",
    "from skimage.measure import label, regionprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_video_frames(analysisDir, videoDir, video_name):\n",
    "    ''' Convert video to .tiff frames '''\n",
    "    # Set Frames Folder\n",
    "    framesDir = os.path.join(analysisDir, 'frames')\n",
    "\n",
    "    # Verify if folder exists and is empty \n",
    "    convert = False\n",
    "    if (not os.path.exists(framesDir)):\n",
    "        print(f'Converting video {video_name} to frames ...')\n",
    "        os.makedirs(framesDir)\n",
    "        convert = True\n",
    "    elif os.path.exists(framesDir) and os.listdir(framesDir) == []:\n",
    "        convert = True\n",
    "\n",
    "    # Convert video to frames if they do not exist\n",
    "    if convert == True:\n",
    "        # Open Video Capture\n",
    "        videoStream = cv2.VideoCapture(videoDir)\n",
    "        # Read Frame\n",
    "        success, frame = videoStream.read()\n",
    "        count = 0\n",
    "        # Read Video\n",
    "        while success:\n",
    "            # Write Frame\n",
    "            cv2.imwrite(os.path.join(framesDir, \"frame_%d.tiff\" % count), frame)  \n",
    "            # Read Frame     \n",
    "            success, frame = videoStream.read()\n",
    "            count += 1\n",
    "        print('Conversion completed!')\n",
    "    else :\n",
    "        print('Frames for this video already exist')\n",
    "\n",
    "    return len([file for file in os.listdir(framesDir) if file.endswith('.tiff')])\n",
    "\n",
    "\n",
    "def tiff_to_pkl(analysisDir):\n",
    "    ''' Save raw image objects to pickle '''\n",
    "    # Set Frames Folder and Pickle Path\n",
    "    framesDir = os.path.join(analysisDir, 'frames')\n",
    "    pklPath = os.path.join(analysisDir, 'rawFrames.pkl')\n",
    "    \n",
    "    # Save raw frames as pickle if they do not exist\n",
    "    if not os.path.exists(pklPath):\n",
    "        print('Saving raw frames as pickle ...')\n",
    "        rawFrames = pims.open(os.path.join(framesDir, '*.tiff'))\n",
    "        with open(pklPath, 'wb') as f:\n",
    "            pickle.dump(rawFrames, f)\n",
    "        print('Pickle saved!')\n",
    "    return pklPath\n",
    "\n",
    "def load_rawFrames(pklPath):\n",
    "    ''' Load raw image objects from pickle '''\n",
    "    with open(pklPath, 'rb') as f:\n",
    "        rawFrames_loaded = pickle.load(f)\n",
    "    return rawFrames_loaded\n",
    "\n",
    "def video_time(videoDir, nFrames):\n",
    "    ''' Get video time and fps '''\n",
    "    # Open Video Capture\n",
    "    videoStream = cv2.VideoCapture(videoDir)\n",
    "    # Fps\n",
    "    fps = videoStream.get(cv2.CAP_PROP_FPS)\n",
    "    # Total Time\n",
    "    tVideo = nFrames/fps\n",
    "    return fps, tVideo\n",
    "\n",
    "\n",
    "@pims.pipeline\n",
    "def crop(img, df_row: pd.DataFrame):\n",
    "    ''' Crop the image to select the region of interest '''\n",
    "    x_min = df_row['x_min'].values[0]\n",
    "    x_max = df_row['x_max'].values[0]\n",
    "    y_min = df_row['y_min'].values[0]\n",
    "    y_max = df_row['y_max'].values[0]\n",
    "    return img[y_min:y_max, x_min:x_max]\n",
    "\n",
    "@pims.pipeline\n",
    "def preprocess(image, df_row: pd.DataFrame):\n",
    "    ''' Apply image processing functions to return a binary image '''\n",
    "    # Convert images to grayscale\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Crop image\n",
    "    image = crop(image, df_row)\n",
    "    # Gaussian adaptive thresholding\n",
    "    par1 = df_row['AdThrParam1'].values[0]\n",
    "    par2 = df_row['AdThrParam2'].values[0]\n",
    "    image = cv2.adaptiveThreshold(image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv2.THRESH_BINARY,par1,par2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_df(frames, features_path, trajectories_path, videoDir, df_row: pd.DataFrame):\n",
    "    ''' Get dataframe with features for each detected landmark '''\n",
    "    # Create empty dataframe to storage landmarck features\n",
    "    video_features = pd.DataFrame()\n",
    "   \n",
    "    # Check if features dataframe already exists\n",
    "    if os.path.exists(features_path):\n",
    "        print(\"Features dataframe already exists.\")\n",
    "        # Read features dataframe\n",
    "        video_features = pd.read_csv(features_path, sep=';')\n",
    "    else:\n",
    "        for num, img in enumerate(frames):\n",
    "            # Create figure instance to save image plot\n",
    "            height, width = img.shape[:2]\n",
    "            white = util.dtype_limits(img)[1]\n",
    "            label_image = label(img, background=white)\n",
    "            # Find landmarks in each frame\n",
    "            nParticles = 0\n",
    "            for region in regionprops(label_image, intensity_image=img):\n",
    "                # Everywhere in the image, skip small and large areas\n",
    "                if region.area < df_row['min_area'].values[0] or region.area > df_row['max_area'].values[0]:\n",
    "                    continue\n",
    "                # On the top of the image, skip small area with a second threshold\n",
    "                if region.centroid[0] < 1000 and region.area < 14:\n",
    "                    continue\n",
    "                # Ensure centroids are confined between 0.2-0.8 of the total height and width\n",
    "                if not (df_row['min_height'].values[0] * height <= region.centroid[0] <= df_row['max_height'].values[0] * height and\n",
    "                        df_row['min_width'].values[0] * width <= region.centroid[1] <= df_row['max_width'].values[0] * width):\n",
    "                    continue\n",
    "                # Ensure circularity for each landmarck\n",
    "                if region.minor_axis_length/region.major_axis_length < df_row['axis_ratio'].values[0]:\n",
    "                    continue\n",
    "                # Store features which survived to the criterions\n",
    "                nParticles += 1\n",
    "                aux_row = [{'y': region.centroid[0],\n",
    "                        'x': region.centroid[1],\n",
    "                        'frame': num,\n",
    "                        'video_path': videoDir,\n",
    "                        },]\n",
    "                video_features = pd.concat([video_features, pd.DataFrame(aux_row)], ignore_index=True)\n",
    "        # Save features dataframe\n",
    "        video_features.to_csv(features_path, sep=';')\n",
    "        print(\"Obtained features dataframe.\")\n",
    "\n",
    "        \n",
    "    # Get initial trajectories dataframe\n",
    "    findLostParticles = False\n",
    "    if os.path.exists(trajectories_path):\n",
    "        print(\"Trajectories dataframe already exists.\")\n",
    "        # Read trajectories dataframe\n",
    "        video_trajectories = pd.read_csv(trajectories_path, sep=';')\n",
    "    else:\n",
    "        # Link features to obtain trajectories\n",
    "        video_trajectories = tp.link(video_features, search_range=50 , memory=1000)\n",
    "        # Find frames with wrong number of particles\n",
    "        wrong_frames = video_features['frame'].value_counts()\n",
    "        wrong_frames = wrong_frames[wrong_frames != df_row['nParticles'].values[0]].index.tolist()\n",
    "        print(f\"{len(wrong_frames)} frames ({len(wrong_frames)/len(frames)*100:.1f}%) have the wrong number of particles (different than {df_row['nParticles'].values[0]})\")\n",
    "        # Activate flag to find lost particles if there are frames with wrong number of particles, else save dataframe\n",
    "        if len(wrong_frames) > 0 :\n",
    "            wrong_frames = sorted(wrong_frames)\n",
    "            print(f\"{wrong_frames} have the wrong number of particles\")\n",
    "            findLostParticles = True\n",
    "        else: \n",
    "            video_trajectories.to_csv(trajectories_path, sep=';')\n",
    "            print(\"Obtained trajectories dataframe.\")\n",
    "\n",
    "    return video_features, video_trajectories, findLostParticles\n",
    "\n",
    "\n",
    "def find_lost_particles(t, nFrames, trajectories_path):\n",
    "    ''' Find lost particles between frames '''\n",
    "    # Initialize lists to store particles to append or remove\n",
    "    particleRemove = []\n",
    "    particleFill = []\n",
    "    # Iterate over unique particles and decide to append or remove them\n",
    "    print(\"Particles detected:\")\n",
    "    for iParticle in np.unique(t['particle'].values):\n",
    "        # Get particle data\n",
    "        tParticle = t[t['particle'] == iParticle]\n",
    "        print(iParticle, len(tParticle['y'].values))\n",
    "        # Append (>95% frames number) or remove particles\n",
    "        if len(tParticle['y'].values) > 0.9*nFrames and len(tParticle['y'].values) != nFrames:\n",
    "            particleFill.append(iParticle)\n",
    "        elif len(tParticle['y'].values) < nFrames:\n",
    "            particleRemove.append(iParticle)\n",
    "    print(f\"Particles to remove: {particleRemove}\")\n",
    "    print(f\"Particles to keep: {particleFill}\")\n",
    "    \n",
    "    # Remove Particles       \n",
    "    for iParticle in particleRemove:\n",
    "        t.drop(t[(t['particle'] == iParticle) ].index, inplace=True)\n",
    "    # Fill Particles with previous or next frame data\n",
    "    for iParticle in particleFill:\n",
    "        # Frames where the particle exists\n",
    "        framesParticle = t[t['particle'] == iParticle][\"frame\"].values \n",
    "        # Frames where the particle is missing\n",
    "        missing = [x for x in range(nFrames) if x not in set(framesParticle)] \n",
    "        for iFrame in missing[::-1]: # Start iterating in the last missing frame\n",
    "            # Fill with value from closest frame where particle exists\n",
    "            closestFrame = min(framesParticle, key=lambda x:abs(x-iFrame))\n",
    "            # Get row with particle info in the closest frame\n",
    "            iFill = t[(t['particle'] == iParticle) & (t['frame'] == closestFrame) ].index \n",
    "            # Add a new row with the particle info in the missing frame\n",
    "            row = t.loc[iFill[0]].copy()\n",
    "            row['frame'] = iFrame\n",
    "            # Add row to the end of the dataframe\n",
    "            t = pd.concat([t, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "    # Sort dataframe by frame and particle\n",
    "    t = t.sort_values(by=['frame', 'particle']).reset_index(drop=True)\n",
    "    t = t.astype({'particle': int})\n",
    "    # Save trajectories dataframe to csv\n",
    "    t.to_csv(trajectories_path, sep=';', index=False)\n",
    "\n",
    "    # Print paticles list after fill/remove missing values\n",
    "    print(\"Particles after fill/remove missing values:\")\n",
    "    for iParticle in np.unique(t['particle'].values):\n",
    "        tParticle = t[t['particle'] == iParticle]\n",
    "        print(int(iParticle), len(tParticle['y'].values))\n",
    "\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extreme_frame(subtrajectories_df: pd.DataFrame):\n",
    "    ''' Get frame with maximum displacement from frame 0 '''\n",
    "    # Get sorted list of particles\n",
    "    particles = sorted(subtrajectories_df['particle'].unique())\n",
    "    # Find Extreme Frame Based on Maximum Displacement from Frame 0 - first particle only\n",
    "    ti = subtrajectories_df[subtrajectories_df['particle'] == particles[0]]\n",
    "    # Get the initial position (frame 0)\n",
    "    x0 = ti['x'].values[0]\n",
    "    y0 = ti['y'].values[0]\n",
    "    # Calculate the displacement (Euclidean distance) from frame 0 for each frame\n",
    "    ti['displacement'] = np.sqrt((ti['x'].values - x0)**2 + (ti['y'].values - y0)**2)\n",
    "    # Find the index of the frame with the maximum displacement\n",
    "    maxDisp, iFramePressure = np.max(ti['displacement'].values), np.argmax(ti['displacement'].values)\n",
    "    # Print results\n",
    "    print(f\"Maximum displacement: {maxDisp}\")\n",
    "    print(f\"Frame with maximum displacement: {iFramePressure}\")\n",
    "    return maxDisp, iFramePressure\n",
    "\n",
    "def plot_trajectories(subtrajectories_df: pd.DataFrame, frames, folderAnalysis, iFramePressure: int, videoName: str):\n",
    "    ''' Plot trajectories in undeformed and deformed gel '''\n",
    "    # Define color map for trajectories\n",
    "    cmap = matplotlib.colormaps.get_cmap('jet')\n",
    "    # Plot Trajectories in Undeformed and Deformed Gel\n",
    "    for f in [0, iFramePressure]:\n",
    "        # Get particles in frame f\n",
    "        thresholds = sorted([elem for elem in subtrajectories_df[subtrajectories_df[\"frame\"] == f]['particle'].values])\n",
    "        colormap = cmap(np.linspace(0.1, 1.0, len(thresholds) + 1))\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        particleList = sorted(subtrajectories_df['particle'].unique())\n",
    "        # Plot trajectories (loop required only to personalize color for each trajectory)\n",
    "        for idParticle, particle in enumerate(particleList):\n",
    "            subtrajectories_df_particle = subtrajectories_df[subtrajectories_df['particle'] == particle]\n",
    "            tp.plot_traj(subtrajectories_df_particle, superimpose = frames[f], ax=ax, plot_style={'color': colormap[idParticle+1]})\n",
    "        # Save figure in analysis folder\n",
    "        fig.savefig(os.path.join(folderAnalysis, videoName + f'_trajs_f{f}.png'), dpi=300)\n",
    "        plt.close(fig)\n",
    "        print(f\"Trajectories for frame {f} plotted.\")\n",
    "\n",
    "def plot_markers(df_trajectories: pd.DataFrame, frames, folderAnalysis, idFrame: list, videoName: str):\n",
    "    ''' Plot markers in frames '''\n",
    "    slitCategory = \"particle\"\n",
    "    # Plot markers in frames\n",
    "    for id in idFrame:\n",
    "        # Plot markers with personalized color for each particle\n",
    "        cmap = matplotlib.colormaps.get_cmap('jet')\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        thresholds = sorted([elem for elem in df_trajectories[df_trajectories[\"frame\"] == id][slitCategory].values]) # threshold markers by particle_id\n",
    "        tp.annotate(df_trajectories[df_trajectories[\"frame\"] == id], frames[id], ax=ax,  split_category=slitCategory, split_thresh=thresholds, color= cmap(np.linspace(0.1, 1.0, len(thresholds)+1)))\n",
    "        ax.set_xlabel('x [px]')\n",
    "        ax.set_ylabel('y [px]')\n",
    "        # Normalize & Apply ColorBar \n",
    "        norm = matplotlib.colors.Normalize(vmin=0.1*len(thresholds), vmax=1.0*len(thresholds)) \n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm) \n",
    "        sm.set_array([]) \n",
    "        plt.colorbar(sm, ticks=np.linspace(1, len(thresholds), len(thresholds))) \n",
    "        # Save figure in analysis folder\n",
    "        fig.savefig(os.path.join(folderAnalysis, videoName + f\"_marks_f{id}.png\"), dpi=300)\n",
    "        plt.close(fig)\n",
    "\n",
    "def get_triangles(subtrajectories_df: pd.DataFrame, frames, idFramePressure: int, folderAnalysis, video_name: str):\n",
    "    ''' Find Delaunay triangles of dataframe subtrajectories '''\n",
    "    for idFrame in [0, idFramePressure]:    \n",
    "        # Extract points from dataframe, sort them by particle id\n",
    "        points = subtrajectories_df[subtrajectories_df['frame'] == idFrame][['x', 'y', 'particle']].values\n",
    "        points = points[points[:,2].argsort()][:,:2]\n",
    "        # Compute Delaunay triangulation\n",
    "        tri = Delaunay(points)\n",
    "        if idFrame == 0:\n",
    "            triangles = tri\n",
    "        # Plot the points and the Delaunay triangulation in frame 0, above the frame\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(frames[idFrame])\n",
    "        plt.triplot(points[:,0], points[:,1], tri.simplices)\n",
    "        plt.plot(points[:,0], points[:,1], 'o')\n",
    "        # Label each particle\n",
    "        for idx, (x, y) in enumerate(tri.points):\n",
    "           plt.text(x, y, f'{idx+1}', fontsize=12, ha='right', color='black')\n",
    "        # Save figure in analysis folder\n",
    "        plt.savefig(os.path.join(folderAnalysis, video_name + f'_tri_f{idFrame}.png'), dpi=300)\n",
    "        plt.close()\n",
    "    return triangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_circle(img, circle_path):\n",
    "    ''' Find the circular contour in the image '''\n",
    "    # Convert to Grayscle Image \n",
    "    imgGray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) \n",
    "    # Filter Image\n",
    "    imgGray = cv2.medianBlur(imgGray, 5)\n",
    "\n",
    "    # Get Image Shape\n",
    "    rows = imgGray.shape[0]\n",
    "    # Define Parameters for Hough Circle Transform\n",
    "    params1 = range(20, 240, 20) \n",
    "    params2 = range(20, 240, 20) \n",
    "    minRadius = [int((1/20)*imgGray.shape[0])] \n",
    "    maxRadius = [int(imgGray.shape[0]/4.5)]\n",
    "\n",
    "    # Iterate over parameters to find the best circle\n",
    "    maxRadDetected = 0\n",
    "    imgCopy = img.copy()\n",
    "    for p1 in params1:\n",
    "        for p2 in params2:\n",
    "            for minR in minRadius:\n",
    "                for maxR in maxRadius:\n",
    "                    # Find the variable circles with circle's center and radius \n",
    "                    circles = cv2.HoughCircles(imgGray, cv2.HOUGH_GRADIENT, 1, rows / 8,\n",
    "                                                param1 = p1, param2 = p2,\n",
    "                                                minRadius=minR, maxRadius=maxR)\n",
    "                    if circles is not None:\n",
    "                        # If HoughCircles finds only one circle\n",
    "                        if circles.shape[1] == 1:\n",
    "                            circles = np.uint16(np.around(circles))\n",
    "                            for i in circles[0, :]:\n",
    "                                # Circle center\n",
    "                                center = (i[0], i[1])\n",
    "                                # Circle radius\n",
    "                                radius = i[2]\n",
    "                                print(f'Radius: {radius}')\n",
    "                                # Store the largest circle\n",
    "                                if radius > maxRadDetected:  \n",
    "                                    imgCopy = img.copy()\n",
    "                                    mask = np.zeros_like(imgGray)\n",
    "                                    cv2.circle(mask, center, radius, (255,0,0), -1)   \n",
    "                                    maxRadDetected = radius\n",
    "                                    cv2.circle(imgCopy, center, radius, (255,0,0), 2)\n",
    "\n",
    "    # Extract Circular Contour\n",
    "    if maxRadDetected > 0:\n",
    "        # Create the mask and save the image only if a circle was detected\n",
    "        cv2.imwrite(circle_path, imgCopy)\n",
    "        # Display and save the image with the detected circle \n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(imgCopy)  \n",
    "        plt.axis('off') \n",
    "        plt.title('Detected Circle') \n",
    "        plt.savefig(circle_path, bbox_inches='tight', pad_inches=0.1)  \n",
    "        plt.close() \n",
    "        # Find the circular contour\n",
    "        _,thresh = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)\n",
    "        contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)       \n",
    "        # Perimeter of the circular contour\n",
    "        perimeter = cv2.arcLength(contours[0][0], True)\n",
    "    else: \n",
    "        perimeter = None\n",
    "\n",
    "    return perimeter, cv2.bitwise_and(img,img, mask=mask), imgCopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_landmarks(xp1, yp1, xp2, yp2):\n",
    "    ''' Compute the distance between two landmarks '''\n",
    "    return ((xp1 - xp2)**2 + (yp1 - yp2)**2)**0.5, xp1-xp2, yp1-yp2\n",
    "\n",
    "def compute_in_plane_strain(triangles, subtrajectories):\n",
    "    ''' Compute the in-plane strain for each triangle '''\n",
    "\n",
    "    # Create a dataframe to store the area and strain of each triangle\n",
    "    dfTriangle = pd.DataFrame(columns=[\"triangule\", \"area\", \"frame\", \"strain\", \"strain_xx\", \"strain_yy\"])\n",
    "\n",
    "    # Get sorted list of particles\n",
    "    particles_list = sorted(subtrajectories['particle'].unique())\n",
    "\n",
    "    # Compute the area and strain for each triangle\n",
    "    for iTriangle in triangles.simplices:\n",
    "        # Get the particles that form the triangle\n",
    "        l1, l2, l3 = iTriangle\n",
    "\n",
    "        # Get the x and y coordinates of each particles\n",
    "        l1x = subtrajectories[subtrajectories['particle'] == particles_list[l1]]['x'].values\n",
    "        l1y = subtrajectories[subtrajectories['particle'] == particles_list[l1]]['y'].values\n",
    "        l2x = subtrajectories[subtrajectories['particle'] == particles_list[l2]]['x'].values\n",
    "        l2y = subtrajectories[subtrajectories['particle'] == particles_list[l2]]['y'].values\n",
    "        l3x = subtrajectories[subtrajectories['particle'] == particles_list[l3]]['x'].values\n",
    "        l3y = subtrajectories[subtrajectories['particle'] == particles_list[l3]]['y'].values\n",
    "        # print(f'Triangle {iTriangle}, {l1x, l1y, l2x, l2y, l3x, l3y}')\n",
    "\n",
    "        # Compute distances between landmarks and x and y components in frame 0\n",
    "        L012, L012_x, L012_y = distance_landmarks(l1x[0], l1y[0], l2x[0], l2y[0])\n",
    "        L013, L013_x, L013_y = distance_landmarks(l1x[0], l1y[0], l3x[0], l3y[0])\n",
    "        L023, L023_x, L023_y = distance_landmarks(l2x[0], l2y[0], l3x[0], l3y[0])\n",
    "\n",
    "        # Initialize arrays to store the strain components\n",
    "        strain12 = np.zeros((len(l1x)))\n",
    "        strain13 = np.zeros((len(l1x)))\n",
    "        strain23 = np.zeros((len(l1x)))\n",
    "        strain12_xx = np.zeros((len(l1x)))\n",
    "        strain13_xx = np.zeros((len(l1x)))\n",
    "        strain23_xx = np.zeros((len(l1x)))\n",
    "        strain12_yy = np.zeros((len(l1x)))\n",
    "        strain13_yy = np.zeros((len(l1x)))\n",
    "        strain23_yy = np.zeros((len(l1x)))\n",
    "        strain = np.zeros((len(l1x)))\n",
    "        strain_xx = np.zeros((len(l1x)))\n",
    "        strain_yy = np.zeros((len(l1x)))\n",
    "        area = np.zeros((len(l1x)))\n",
    "\n",
    "        # Compute the area and strain for each frame f\n",
    "        for i in range(len(l1x) - 1):\n",
    "            # Compute the distances between landmarks and x and y components in frame f\n",
    "            LP12, LP12_x, LP12_y = distance_landmarks(l1x[i + 1], l1y[i + 1], l2x[i + 1], l2y[i + 1])\n",
    "            LP13, LP13_x, LP13_y = distance_landmarks(l1x[i + 1], l1y[i + 1], l3x[i + 1], l3y[i + 1])\n",
    "            LP23, LP23_x, LP23_y = distance_landmarks(l2x[i + 1], l2y[i + 1], l3x[i + 1], l3y[i + 1])\n",
    "            # Compute the strain components\n",
    "            strain12[i] = (LP12 - L012) / L012\n",
    "            strain13[i] = (LP13 - L013) / L013\n",
    "            strain23[i] = (LP23 - L023) / L023\n",
    "            strain12_xx[i] = (LP12_x - L012_x) / L012_x\n",
    "            strain13_xx[i] = (LP13_x - L013_x) / L013_x\n",
    "            strain23_xx[i] = (LP23_x - L023_x) / L023_x\n",
    "            strain12_yy[i] = (LP12_y - L012_y) / L012_y\n",
    "            strain13_yy[i] = (LP13_y - L013_y) / L013_y\n",
    "            strain23_yy[i] = (LP23_y - L023_y) / L023_y\n",
    "            # Compute the average in-plane strain\n",
    "            strain[i] = (strain12[i] + strain13[i] + strain23[i]) / 3\n",
    "            strain_xx[i] = (strain12_xx[i] + strain13_xx[i] + strain23_xx[i]) / 3\n",
    "            strain_yy[i] = (strain12_yy[i] + strain13_yy[i] + strain23_yy[i]) / 3\n",
    "            # Compute the area of the triangle\n",
    "            area[i] = 0.5 * abs(l1x[i + 1] * (l2y[i + 1] - l3y[i + 1]) + l2x[i + 1] * (l3y[i + 1] - l1y[i + 1]) + l3x[i + 1] * (l1y[i + 1] - l2y[i + 1]))\n",
    "\n",
    "        # Smooth the strain and area data\n",
    "        strainSmooth = scipy.signal.savgol_filter(strain, 150, 2, mode='nearest')\n",
    "        strainSmooth_xx = scipy.signal.savgol_filter(strain_xx, 150, 2, mode='nearest')\n",
    "        strainSmooth_yy = scipy.signal.savgol_filter(strain_yy, 150, 2, mode='nearest')\n",
    "        areaSmooth = scipy.signal.savgol_filter(area, 150, 2, mode='nearest')\n",
    "\n",
    "        # Store the area and strain data in the dataframe\n",
    "        dfTriangle.loc[len(dfTriangle)] = {\"triangule\": iTriangle, \"area\": areaSmooth, \"frame\": range(len(l1x)), \"strain\": strainSmooth, \"strain_xx\": strainSmooth_xx, \"strain_yy\": strainSmooth_yy}\n",
    "\n",
    "    return dfTriangle\n",
    "\n",
    "def get_plots(df_triangles, tVideo, nFrames, folderName, videoName):\n",
    "    ''' Save .csv file for area and strain of each triangle '''\n",
    "    # Explode list quantities: area, frame, strain\n",
    "    dfExplode = df_triangles.explode(['area','frame','strain','strain_xx','strain_yy'])\n",
    "\n",
    "    # Insert time column\n",
    "    dfExplode[\"time\"] = (tVideo/nFrames) * dfExplode[\"frame\"]\n",
    "    # Reset dataframe index\n",
    "    dfExplode = dfExplode.reset_index()\n",
    "    dfExplode.to_csv(os.path.join( folderName, videoName + '_results.csv'), sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    features, trajectories = pd.DataFrame(), pd.DataFrame()\n",
    "    rawFramesDict, framesDict = {}, {}\n",
    "    dfExtremeFrame = pd.DataFrame(columns=['file', 'frame'])\n",
    "\n",
    "    # Set video folder\n",
    "    video = \"static_50-mbar.mp4\"\n",
    "    video_name = video.split(\".\")[0]\n",
    "    videoDir = os.path.join(\"video\", video)\n",
    "    print(\"Video:\", video)\n",
    "    # Create analysis folder\n",
    "    analysisDir = os.path.join(os.getcwd(), video_name + \"_analysis\")\n",
    "    if (not os.path.exists(analysisDir)):\n",
    "        os.makedirs(analysisDir)\n",
    "    print(\"Analysis saved in:\", analysisDir)\n",
    "    # Convert video to frames \n",
    "    nFrames = convert_video_frames(analysisDir, videoDir, video_name)\n",
    "    # Save rawFrames as pickle\n",
    "    rawFrames_pklPath = tiff_to_pkl(analysisDir)\n",
    "    # Load pkl data\n",
    "    rawFrames = load_rawFrames(rawFrames_pklPath)\n",
    "    print(\"Raw frames saved in:\", rawFrames_pklPath)\n",
    "    # Get video info\n",
    "    fps, tVideo = video_time(videoDir, nFrames)\n",
    "    print(f\"Number of Frames: {nFrames}\")\n",
    "    print(\"FPS:\",fps)\n",
    "    print(\"Video Time [s]:\",tVideo)\n",
    "    # Define parameters for preprocess raw frames \n",
    "    x_min = 50\n",
    "    x_max = 650\n",
    "    y_min = 350\n",
    "    y_max = 1000\n",
    "    AdThrParam1 = 71\n",
    "    AdThrParam2 = 5\n",
    "    min_area = 150\n",
    "    max_area = 4500\n",
    "    min_height = 0.15\n",
    "    min_width = 0.25\n",
    "    max_height = 0.75\n",
    "    max_width = 0.95\n",
    "    axis_ratio = 0.4\n",
    "    nParticles = 10\n",
    "    # Save preprocess parameters in .pkl file\n",
    "    dfParams = pd.DataFrame([[video, x_min, x_max, y_min, y_max, AdThrParam1, AdThrParam2, min_area, max_area, min_height, min_width, max_height, max_width, axis_ratio, nParticles]], \n",
    "                            columns=['video_name', 'x_min', 'x_max', 'y_min', 'y_max', 'AdThrParam1', 'AdThrParam2', 'min_area', 'max_area', 'min_height', 'min_width', 'max_height', 'max_width', 'axis_ratio', 'nParticles'])\n",
    "    params_pklPath = os.path.join(analysisDir, 'preprocessParameters.pkl')\n",
    "    dfParams.to_pickle(params_pklPath)\n",
    "    print(\"Preprocess parameters saved in:\", params_pklPath)\n",
    "    # Preprocess raw frames\n",
    "    frames = preprocess(rawFrames, dfParams)\n",
    "    print(\"Images preprocessing is completed.\")\n",
    "    # Verify if the image is correctly cropped and thresholded\n",
    "    print(\"Cropped and Thresholded Frame 0:\")\n",
    "    plt.imshow(frames[0])\n",
    "    # Find features in frames, get traectories and solve lost particles\n",
    "    features_path = os.path.join(analysisDir, video_name + '_features.csv')\n",
    "    trajectories_path = os.path.join(analysisDir, video_name + '_trajectories.csv')\n",
    "    subfeatures, subtrajectories, findLostParticles = get_features_df(frames,\n",
    "                                                                    features_path, trajectories_path, \n",
    "                                                                    videoDir, dfParams) \n",
    "    if findLostParticles:\n",
    "        subtrajectories = find_lost_particles(subtrajectories, nFrames, trajectories_path)\n",
    "    print(\"Features dataframe saved in:\", features_path)\n",
    "    print(\"Trajectories dataframe saved in:\", trajectories_path)\n",
    "    # Get extreme frame based on maximum displacement from frame 0\n",
    "    maxDisp, iFramePressure = get_extreme_frame(subtrajectories)\n",
    "    # Plot trajectories and markers in frames\n",
    "    plot_markers(df_trajectories = subtrajectories, frames = crop(rawFrames, dfParams), folderAnalysis=analysisDir, \n",
    "                 idFrame = [0, iFramePressure], videoName= video_name)\n",
    "    plot_trajectories(subtrajectories_df=subtrajectories, frames=crop(rawFrames, dfParams), \n",
    "                      folderAnalysis=analysisDir, iFramePressure=iFramePressure, videoName=video_name)\n",
    "    # Find circular contour in the image\n",
    "    circle_path = os.path.join(analysisDir, video_name + '_circle.png')\n",
    "    pPix, imgMask, imgSegmented = find_circle(rawFrames[0], circle_path)\n",
    "    # Get Delaunay triangles and compute in-plane strain\n",
    "    triangles = get_triangles(subtrajectories, crop(rawFrames, dfParams), iFramePressure,folderAnalysis=analysisDir, video_name=video_name)\n",
    "    df_triangles = compute_in_plane_strain(triangles, subtrajectories=subtrajectories)\n",
    "    # Extract strain and area quantities from dataframe to csv\n",
    "    results_path = os.path.join(analysisDir, video_name + '_results.csv')\n",
    "    get_plots(df_triangles, tVideo, nFrames, analysisDir, video_name)\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cell-tracking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
